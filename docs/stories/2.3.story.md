# 2.3 — Auto-approve vs Human Review Routing + Logging

## Status
Approved

## Story
**As a** system,
**I want** to route cheques to auto-approve when all gates pass and confidences exceed threshold, otherwise to human review,
**so that** I can record structured reasons for decisions and guarantee correctness.

## Acceptance Criteria
1. If all required fields ≥ threshold and validations pass → auto-approve and mark `stp=true`.
2. Else → route to human review with reason codes and low-confidence field list.
3. All decisions logged with correlation IDs and persisted in audit JSON.
4. Unit tests cover routing branches; integration tests verify end-to-end behavior.

## Dev Notes (Architecture References)
- Confidence & Routing [Source: architecture/components.md#7-confidence-routing]
- Human-in-the-Loop [Source: architecture/components.md#8-human-in-the-loop-ui]
- Data model `cheque.status`, `cheque.audit_json`, `cheque.stp` [Source: architecture/data-model-core-tables.md#cheque]
- Coding standards & logging [Source: architecture/coding-standards.md]
- Testing [Source: architecture/testing-strategy.md]

### Testing
- Test file location: `backend/tests/services/test_routing.py`
- Standards: follow `docs/architecture/coding-standards.md`; target ≥ 85% coverage on routing logic
- Frameworks: `pytest`
- Story-specific: verify both branches (auto-approve vs review) and audit JSON content per `testing-strategy.md`

## Tasks / Subtasks
- Implement router `backend/app/services/routing.py` with auto-approve and review branches.
- Add audit entries with reason codes and low-confidence fields.
- Tests under `backend/tests/services/test_routing.py` and integration suite.

## Project Structure Notes
- Keep routing logic isolated from UI; UI consumes routing outcomes.

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|

## Dev Agent Record
### Agent Model Used

### Debug Log References

### Completion Notes List

### File List

## QA Results

